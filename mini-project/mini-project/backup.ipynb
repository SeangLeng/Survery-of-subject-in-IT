{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"font-weight:bold; font-family:monospace; font-size:18px;\">Step 1 - Topic: Forecast the future demand of short courses and expert courses in 2024. </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"font-weight:bold; font-family:monospace; font-size:18px;\">Step 2 - Data Collection </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###     <pre style=\"font-weight:bold; font-size:17px\">Sources:</pre>\n",
    "<ul style=\"line-height: 1.5; font-family:monospace\">\n",
    "<li>Short course schools</li>\n",
    "  <ul>\n",
    "    <li>CSTAD</li>\n",
    "    <li>Ant Training center</li>\n",
    "    </ul>\n",
    "<li>Survey</li>\n",
    "<li>Job announcement website</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-weight: bold; color: blue; font-family:monospace\">1.   Scrape data from Ant Training center</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import urllib.error\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# Define the URL of the main page with the list of students\n",
    "main_page_url = \"http://training.antkh.com/students/\"\n",
    "\n",
    "# Send an HTTP GET request to the main page and parse it with Beautiful Soup\n",
    "main_page_response = urlopen(main_page_url)\n",
    "main_page_soup = BeautifulSoup(main_page_response, \"lxml\")\n",
    "\n",
    "# Initialize a list to store student data\n",
    "student_data_list = []\n",
    "\n",
    "# Find all the student rows in the main page\n",
    "student_rows = main_page_soup.find_all(\"tr\")\n",
    "\n",
    "list_rows = []\n",
    "\n",
    "# Loop through each student row\n",
    "for row in student_rows[1:]:\n",
    "    cells = row.find_all('td')\n",
    "    str_cells = str(cells)\n",
    "\n",
    "    # Clean the HTML tags from the cell content\n",
    "    clean = re.compile('<.*?>')\n",
    "    clean2 = (re.sub(clean, '', str_cells))\n",
    "\n",
    "    # Initialize variables for Khmer name and University\n",
    "    km_name = \"\"\n",
    "    university = \"\"\n",
    "\n",
    "    # Split the cleaned cell content into Khmer name and University\n",
    "    parts = clean2.split(',')\n",
    "    \n",
    "    if len(parts) >= 2:\n",
    "        km_name, university = parts[0], parts[1]\n",
    "\n",
    "    # Extract the href attribute from the first \"a\" element within the row\n",
    "    student_link = cells[0].find(\"a\")\n",
    "    href_value = student_link.get(\"href\")\n",
    "    try:\n",
    "   \n",
    "         # Construct the URL for the detailed student page\n",
    "        detailed_page_url = f\"http://training.antkh.com/students/{href_value}\"\n",
    "\n",
    "        # Send an HTTP GET request to the detailed page and parse it with Beautiful Soup\n",
    "        detailed_page_response = urlopen(detailed_page_url)\n",
    "        detailed_page_soup = BeautifulSoup(detailed_page_response, \"lxml\")\n",
    "\n",
    "        # Extract additional information from the detailed page\n",
    "        academic_info_elem = detailed_page_soup.find(\"div\", id=\"c_pAcademic\")\n",
    "        academic_info = academic_info_elem.get_text(strip=True) if academic_info_elem else \"\"\n",
    "        academic_year_match = re.search(r'(\\d{4})', academic_info)\n",
    "        academic_year = academic_year_match.group(1) if academic_year_match else 0\n",
    "\n",
    "        study_info_elem = detailed_page_soup.find(\"div\", class_=\"study-info\")\n",
    "        study_info_items = study_info_elem.find_all(\"li\")\n",
    "        courses = [item.get_text() for item in study_info_items]\n",
    "        courses_str = ', '.join(courses)\n",
    "\n",
    "        profile_content = detailed_page_soup.find(\"div\", class_=\"inner-content\")\n",
    "        eng_name = profile_content.find(\"h2\").get_text()\n",
    "    except urllib.error.URLError as e:\n",
    "        print(f\"Failed to fetch the page: {e}\")\n",
    "\n",
    "    # Append the extracted data to the list\n",
    "    list_rows.append([eng_name, km_name, university, courses_str, academic_year])\n",
    "\n",
    "# Create a DataFrame with the extracted data\n",
    "df = pd.DataFrame(list_rows, columns=[\"English Name\", \"Khmer Name\", \"University\", \"Courses\", \"Academic Year\", ])\n",
    "\n",
    "# Remove square brackets from Khmer Name, University, and Courses columns\n",
    "df[\"Khmer Name\"] = df[\"Khmer Name\"].str.strip(\"[\")\n",
    "df[\"University\"] = df[\"University\"].str.strip(\"]\")\n",
    "df[\"Courses\"] = df[\"Courses\"].str.strip(\"[]\")\n",
    "\n",
    "# New DataFrame containing only rows with academic year > 2020\n",
    "filtered_df = df[df[\"Academic Year\"].astype(int) > 2020]\n",
    "\n",
    "# Filter 100 records from each of the academic years 2017, 2018, and 2019\n",
    "academic_years = [2017, 2018, 2019]\n",
    "filtered_records = []\n",
    "\n",
    "for year in academic_years:\n",
    "    records_for_year = df[pd.to_numeric(df[\"Academic Year\"], errors='coerce', downcast='integer') == year]\n",
    "    if len(records_for_year) >= 100:\n",
    "        random_records = records_for_year.sample(n=100, random_state=42)\n",
    "        filtered_records.append(random_records)\n",
    "\n",
    "# Concatenate the filtered records to the existing filtered_df\n",
    "filtered_df = pd.concat([filtered_df] + filtered_records)\n",
    "\n",
    "# Save the filtered data to a CSV file\n",
    "filtered_df.to_csv(\"ant_training_students.csv\", index=False)\n",
    "filtered_df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-weight: bold; color: blue; font-family:monospace\">2.   Import data from CSTAD short course, survey data and Ant training data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cstad_file_path = 'CSTAD_Short_Course_Data.csv'\n",
    "cstad_df = pd.read_csv(cstad_file_path)\n",
    "\n",
    "ant_file_path = 'ant_training_students.csv'\n",
    "ant_df = pd.read_csv(ant_file_path)\n",
    "\n",
    "survey_file_path = 'IT_Course_Survey.csv'\n",
    "survey_df = pd.read_csv(survey_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-weight: bold; color: blue; font-family:monospace\">3.   More data cleansing on Ant training data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessicasun/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n"
     ]
    }
   ],
   "source": [
    "# Split the 'Courses' column by ',' and create a new DataFrame\n",
    "split_df = ant_df['Courses'].str.split(',').explode().reset_index(drop=True)\n",
    "\n",
    "# Duplicate the other columns for the split rows\n",
    "new_df = ant_df.drop(columns=['Courses']).loc[ant_df.index.repeat(ant_df['Courses'].str.count(',') + 1)].reset_index(drop=True)\n",
    "\n",
    "# Assign the split values to the 'Courses' column\n",
    "new_df['Courses'] = split_df\n",
    "\n",
    "# Remove the 'Khmer Name' column\n",
    "new_df.drop(columns=\"Khmer Name\", inplace=True)\n",
    "\n",
    "# Add a new column \"Short course school\" with the value \"ANT\"\n",
    "new_df['Short course school'] = 'ANT'\n",
    "\n",
    "# Handle potential missing or invalid values\n",
    "new_df['Courses'].fillna('', inplace=True)\n",
    "\n",
    "# Modify course\n",
    "new_df['Courses'] = new_df['Courses'].str.strip()\n",
    "new_df.rename(columns={'Courses': 'Course'}, inplace=True)\n",
    "new_df = new_df[new_df['Course'].str.strip() != '']\n",
    "\n",
    "course_mapping = {\n",
    "    'HTML+HTML5&CSS': 'Web Design',\n",
    "    'Website Design With CSS': 'Web Design',\n",
    "    'CSS3 & Bootstrap': 'Web Design',\n",
    "    'C++OOP': 'C++',\n",
    "    'JavaScript + Jquery': 'Web Design',\n",
    "    'C# Beginning': 'C#',\n",
    "    'Node.js +Express': 'Node JS',\n",
    "    'Java Programing' : 'Java',\n",
    "    'Mobile App (Flutter)': 'Flutter',\n",
    "    'C/C++': 'C++',\n",
    "    'Web Development': 'Full stack',\n",
    "    'C# Database Programming': 'C#',\n",
    "    'OOP PHP': 'PHP',\n",
    "    'Android Application Development': 'Flutter',\n",
    "    'HTML': 'Web Design',\n",
    "    'PHP & My SQL': 'PHP'\n",
    "    }\n",
    "\n",
    "new_df['Course'] = new_df['Course'].replace(course_mapping)\n",
    "new_df['Course'] = new_df['Course'].str.strip()\n",
    "# Remove duplicate row and Change student name column\n",
    "new_df = new_df.drop_duplicates()\n",
    "new_df.rename(columns={'English Name': 'Fullname'}, inplace=True)\n",
    "\n",
    "# Save the final DataFrame to a new CSV file\n",
    "new_df.to_csv('ant_training_students_v2.csv', index=False)\n",
    "new_df.to_excel('ant_training_students_v2.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-weight: bold; color: blue; font-family:monospace\">4.   Combine data from 3 sources</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.rename(columns={'Course': 'Course', 'Academic Year': 'Academic Year'}, inplace=True)\n",
    "survey_df.rename(columns={'Course': 'Course', 'Academic Year': 'Academic Year'}, inplace=True)\n",
    "\n",
    "# Concatenate DataFrames\n",
    "final_df = pd.concat([cstad_df, new_df, survey_df], ignore_index=True)\n",
    "final_df.to_csv('final_dataset.csv', index=False)\n",
    "final_df.to_excel('final_dataset.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
